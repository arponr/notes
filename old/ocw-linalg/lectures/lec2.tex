\section{Elimination}

So let's look at a systematic method of solving systems of equations, namely elimination, and when it succeeds and fails and so on.

\bex
Let's illustrate with the example
\bea
x + 2y + z = 2 \\ 3x+6y+z=12\\4y+7=2,
\eea
or in matrix form,
\[ \mat{1&2&1\\3&8&1\\0&4\\1}\mat{x\\y\\z} = \mat{2\\12\\2}. \]
So we'll mostly be looking at our matrix $\mA$ on the left.

The first step of elimination is to subtract a multiple of the first equation from the second equation to eliminate the $x$ term from the second equation. So the key number in this step is the $x$ term of the first equation; we call the key number at any step the \textit{pivot}. So we can see the multiplier needs to be 3, and then our equation will become
\[ \mat{1&2&1\\0&2&-2\\0&4&1}\mat{x\\y\\z} = \mat{2\\6\\2}. \]
We then want to eliminate the $x$ term of the third equation, in the same way (here the multiplier is 0 because our condition is already satisfied, and so the equation stays the same). 

Then we move to the second pivot is the second row, second column, and we do a similar thing as the first step: we eliminate the $y$ term in the third equation (our multiplier is 2). Then our equation becomes
\[ \mat{1&2&1\\0&2&-2\\0&0&5}\mat{x\\y\\z} = \mat{2\\6\\-10}. \]

Then we call the third row, third column entry our third pivot. And at this point we have turned our matrix $\mA$ into a matrix $\mU$ in \textbf{upper triangular form} (and correspondingly, our vector $\vb$ turns into a vector we name $\vc$). (The purpose of elimination is to get from $\mA$ to $\mU$.)

This upper triangular form is quite important, and it's very important that none of our pivots be zero for anything to work. (One cool property is that the determinant of the matrix is the product of the pivots.) If there is ever a zero in the pivot position during this algorithm, we switch the order of our rows (or equations). If there's ever a case where we have a zero in the pivot position and we have no possible exchanges to fix the situation, then elimination has completely failed, which would mean that there's no single solution to the system. 

Now let's actually find the solution in this case (using \textbf{back substitution}). Our last equation tells us that
\[ 5z = -10, \]
so $z = -2$. Then we plug this into the second equation to get
\[ 2y + 4 = 6\]
so $y = 1$. The we plug this and $z$ into the first equation to get
\[ x = 2.\]
So our solution vector ends up being $\vx = \rvec{2,1,-2}$.

But lets look at the elimination process we just did in terms of matrix operations, namely by matrix multiplication, rather in terms of just manipulating the equations. (We'll only look at the maniuplations on the matrix $\mA$; what happens to the right hand side of the equation follows easily, and can also be done by doing these same matrix products with the 3x4 augmented matrix with the first three columns being $\mA$ and the last being $\vb$.)

So the first step was subtracting three of the first equation from the second equation. This can be representing by the following matrix product:
\[ \mat{1&0&0\\-3&1&0\\0&0&1}\mat{1&2&1\\3&8&1\\0&4&1} = \mat{1&2&1\\0&2&-2\\0&4&1}. \]
We'll call that matrix all the way on the left the elementrry matrix $\mE$, and we'll call this specific one $\mE_{21}$ because it's used to eliminate the term in the second row, first column. 

The second step was to subtract two of the second equation from the third equation. This can be represented in by the following matrix product:
\[ \mE_{32}\mA' = \mat{1&0&0\\0&1&0\\0&-2&1}\mat{1&2&1\\3&8&1\\0&4&1} = \mat{1&2&1\\0&2&-2\\0&0&5}. \]

Notice then, that we can combine all of these steps into just one matrix product. Our answer was $\mU = \mE_{32}\mE_{21}\mA$. So we can consider multiplying $\mA$ by the single matrix $\mE = \mE_{32}\mE_{21}$ (because matrix multiplication is associative). (Note that order of this multiplication is important, because matrix multiplication is not communtative.) Now we could actually multiply to get $\mE$, but there's a better way to do it, and it involves inverse matrices. (So instead of getting from $\mA$ to $\mU$, how do we get from $\mU$ to $\mA$?) The inverses of these elimination step matrices are easy to see, because we just reverse what we did to the system. So instead of subtracting three of row 1 from row 2, we add three of row 1 to row 2 in the inverse. I.e., 
\[ \mat{1&0&0\\3&1&0\\0&0&1}\mat{1&0&0\\-3&1&0\\0&0&1} = \mat{1&0&0\\0&1&0\\0&0&1}. \]
\eex
 
\brm
We said earlier that, even though we didn't need it in this particular example, that we may need to exchange rows in the elimination algorithm. Say we wanted to exchange the two rows in a 2x2 matrix. It's easy to see that this \textbf{permutation matrix} involves reflecting certain rows of the identity matrix, so
\[ \mat{0&1\\1&0}\mat{a&b\\c&d} = \mat{c&d\\a&b}. \]
Now notice that we could not multiply by any matrix on the left of a given matrix to switch its columns. However putting the permutation matrix on the right of our given matrix will accomplish this. This introduces the idea that row operations involve left-multiplication and column operations involve right-multiplications (in matrices, that is).
\erm